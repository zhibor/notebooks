{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an improved version of the prompt:\n",
      "\n",
      "### Expert Spell Checker: Identify and Correct Errors in the Following Text\n",
      "\n",
      "As a seasoned language expert, I need you to thoroughly spell check the text below and provide a corrected version.\n",
      "\n",
      "Please review the following passage carefully, paying attention to any typos, grammatical errors, or punctuation mistakes. Your task is to identify each error and suggest the correct spelling or correction.\n",
      "\n",
      "Here are several tips on writing great prompts:\n",
      "\n",
      "Start by stating that it is an expert in the subject.\n",
      "Put instructions at the beginning of the prompt and use ### or to separate the instruction and context \n",
      "Be specific, descriptive and as detailed as possible about the desired context, outcome, length, format, style, etc\n",
      "\n",
      "The text to be spell checked is:\n",
      "\n",
      "[Insert the text here]\n",
      "\n",
      "Please provide a corrected version of the text, highlighting any errors you found and suggesting the correct spelling or correction.\n",
      "\n",
      "Example: [Insert an example of a corrected text]\n",
      "\n",
      "Note: The improved prompt includes specific instructions for the task, clarifies the expected outcome, and provides an example to illustrate the desired format.\n"
     ]
    }
   ],
   "source": [
    "local_llm = 'llama3'\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull('hardkothari/prompt-maker')\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({'lazy_prompt': 'spell check the text below', 'task': 'spell check'})\n",
    "\n",
    "print(generation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
